#![deny(clippy::all)]

use anyhow::Result;
use clap::Parser;
use llm_client::{LlmConfig, LlmProvider, Prompt, Provider, provider_from_config};
use std::process::Command;
use terminal_core::{Block, run};
use tokio::io::{self, AsyncBufReadExt, BufReader};
use tokio_stream::StreamExt;

#[derive(Parser, Debug)]
#[command(author, version, about)]
struct Cli {
    /// LLM provider to use
    #[arg(long, default_value = "ollama")]
    provider: String,
    /// Model name
    #[arg(long, default_value = "llama3")]
    model: String,
    /// Opt into telemetry
    #[arg(long, default_value_t = false)]
    insecure_telemetry: bool,
}

enum Route {
    Spawn(String),
    Switch(String),
    Exec { cmd: String, rationale: String },
}

struct CommandRouter {
    cfg: LlmConfig,
    provider: Box<dyn LlmProvider>,
}

impl CommandRouter {
    fn new(cfg: LlmConfig) -> Self {
        let provider = provider_from_config(&cfg);
        Self { cfg, provider }
    }

    #[cfg(test)]
    fn with_provider(cfg: LlmConfig, provider: Box<dyn LlmProvider>) -> Self {
        Self { cfg, provider }
    }

    async fn nl_to_shell(&self, line: &str) -> Result<(String, String)> {
        let resp = self
            .provider
            .complete(Prompt {
                text: line.to_string(),
            })
            .await?;
        Ok((resp.text, "generated by ai".into()))
    }

    async fn route(&mut self, line: &str) -> Result<Route> {
        let trimmed = line.trim();
        if trimmed == "bash" || trimmed == "pwsh" || trimmed == "cmd" {
            return Ok(Route::Spawn(trimmed.into()));
        }
        if let Some(rest) = trimmed.strip_prefix("/model ") {
            self.cfg.model = rest.to_string();
            self.provider = provider_from_config(&self.cfg);
            return Ok(Route::Switch(rest.to_string()));
        }
        let (cmd, rationale) = self.nl_to_shell(trimmed).await?;
        Ok(Route::Exec { cmd, rationale })
    }

    async fn handle_line(&mut self, line: &str) -> Result<()> {
        match self.route(line).await? {
            Route::Spawn(shell) => {
                let mut cmd = Command::new(shell);
                let mut stream = run(cmd).await?;
                while let Some(Block { text }) = stream.next().await {
                    println!("{}", text);
                }
            }
            Route::Switch(model) => {
                println!("Switched model to {model}");
            }
            Route::Exec { cmd, rationale } => {
                println!("# AI: {rationale}");
                let mut command = if cfg!(target_os = "windows") {
                    let mut c = Command::new("cmd");
                    c.arg("/C").arg(&cmd);
                    c
                } else {
                    let mut c = Command::new("sh");
                    c.arg("-c").arg(&cmd);
                    c
                };
                let mut stream = run(command).await?;
                while let Some(Block { text }) = stream.next().await {
                    println!("{}", text);
                }
                println!("exit: 0");
            }
        }
        Ok(())
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    let args = Cli::parse();
    let cfg = LlmConfig {
        provider: match args.provider.as_str() {
            "ollama" => Provider::Ollama,
            "openrouter" => Provider::OpenRouter,
            "aifoundry" => Provider::AIFoundry,
            _ => Provider::Custom,
        },
        base_url: "http://localhost".into(),
        api_key: None,
        model: args.model.clone(),
    };

    if args.insecure_telemetry {
        println!("Telemetry enabled");
    }

    let mut router = CommandRouter::new(cfg);
    let stdin = BufReader::new(tokio::io::stdin());
    let mut lines = stdin.lines();
    while let Some(line) = lines.next_line().await? {
        router.handle_line(&line).await?;
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use rstest::rstest;

    #[derive(Clone)]
    struct FakeProvider;

    use async_trait::async_trait;

    #[async_trait]
    impl LlmProvider for FakeProvider {
        async fn complete(&self, req: Prompt) -> Result<llm_client::Resp> {
            Ok(llm_client::Resp {
                text: format!("echo {}", req.text),
            })
        }
    }

    #[rstest]
    #[case("--provider", "ollama", Provider::Ollama)]
    #[case("--provider", "openrouter", Provider::OpenRouter)]
    fn parse_provider(#[case] flag: &str, #[case] value: &str, #[case] expected: Provider) {
        let cli = Cli::try_parse_from(["test", flag, value]).unwrap();
        let provider = match cli.provider.as_str() {
            "ollama" => Provider::Ollama,
            "openrouter" => Provider::OpenRouter,
            "aifoundry" => Provider::AIFoundry,
            _ => Provider::Custom,
        };
        match (&provider, &expected) {
            (Provider::Ollama, Provider::Ollama) | (Provider::OpenRouter, Provider::OpenRouter) => {
            }
            _ => panic!("mismatch"),
        }
    }

    #[rstest]
    #[tokio::test]
    async fn route_spawn() {
        let cfg = LlmConfig {
            provider: Provider::Ollama,
            base_url: "".into(),
            api_key: None,
            model: "m".into(),
        };
        let mut router = CommandRouter::with_provider(cfg, Box::new(FakeProvider));
        match router.route("bash").await.unwrap() {
            Route::Spawn(s) => assert_eq!(s, "bash"),
            _ => panic!(),
        }
    }

    #[rstest]
    #[tokio::test]
    async fn route_switch() {
        let cfg = LlmConfig {
            provider: Provider::Ollama,
            base_url: "".into(),
            api_key: None,
            model: "m".into(),
        };
        let mut router = CommandRouter::with_provider(cfg, Box::new(FakeProvider));
        match router.route("/model x").await.unwrap() {
            Route::Switch(m) => assert_eq!(m, "x"),
            _ => panic!(),
        }
    }

    #[rstest]
    #[tokio::test]
    async fn route_exec() {
        let cfg = LlmConfig {
            provider: Provider::Ollama,
            base_url: "".into(),
            api_key: None,
            model: "m".into(),
        };
        let mut router = CommandRouter::with_provider(cfg, Box::new(FakeProvider));
        match router.route("list files").await.unwrap() {
            Route::Exec { cmd, rationale: _ } => assert_eq!(cmd, "echo list files"),
            _ => panic!(),
        }
    }
}
